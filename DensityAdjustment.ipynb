{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0c09a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate\n",
    "import netCDF4 as nc\n",
    "#import xarray as xr\n",
    "import scipy.ndimage\n",
    "import scipy as sp\n",
    "#import alphashape\n",
    "from scipy import interpolate\n",
    "#from shapely.geometry import Point\n",
    "#from shapely.geometry.polygon import Polygon\n",
    "from matplotlib import style\n",
    "style.use('ggplot') or plt.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e451d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in picked radargram data. This code assumes that the picked data is presented as\n",
    "# depth below surface.\n",
    "\n",
    "data = pd.read_csv('../Data/DataFromInka/Princess_Ragnild_Coast_airborne_IRHs_20190107_02_depth20220801_working_copy.txt', sep=\" \")\n",
    "\n",
    "# Read in BedMachine netcdf surface data \n",
    "# The surface elevation is read in as \n",
    "\n",
    "# Surface variable name. Change this to the surface variable name in your \n",
    "# BedMachine elevation file:\n",
    "surf_name = 'zs'\n",
    "\n",
    "ds = nc.Dataset('Derwael.nc')\n",
    "\n",
    "# Clean up dataset: remove data not needed\n",
    "\n",
    "data.drop(['year_acq', 'month_acq', 'day_acq', 'surveyID', 'profileID', 'lon', 'lat', 'trace', 'year_pick', 'month_pick', 'day_pick' ],axis=1, inplace=True)\n",
    "\n",
    "# Number of picked layers:\n",
    "\n",
    "layers = 12\n",
    "\n",
    "# The function takes as input a depth and returns the density at that depth. The current \n",
    "# function describes the density profile of an ice core from Derwael Ice Rise. See\n",
    "# doi:10.1002/2013GL058023 . Change this accordingly.\n",
    "\n",
    "def DensityProfile(d):\n",
    "    return 910.0 - 460.0 * np.exp(-0.025*d)\n",
    "\n",
    "# Choose the output path\n",
    "\n",
    "output_path = '../Data/AdjustedRadarStatigraphy/DepthAdjustedStratigraphyElevation.csv'\n",
    "\n",
    "# Some column names need to be correct:\n",
    "# Coordinates should take the form: 'psX', 'psY'\n",
    "# Picked lines should take the form: 'IRH1', 'IRH2', etc.\n",
    "\n",
    "# Headers in working example:\n",
    "# ['psX', 'psY', 'surface', 'base', 'IRH1', 'IRH2', 'IRH3', 'IRH4', 'IRH5',\n",
    "# 'IRH6', 'IRH7', 'IRH8', 'IRH9', 'IRH10', 'IRH11', 'IRH12']\n",
    "\n",
    "# Change column names using this code if need be:\n",
    "    \n",
    "# data = data.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebeca7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns for the corresponding density due to the density profile\n",
    "\n",
    "data['IRH0'] = [0] * len(data)\n",
    "data['AdjDepthIRH0'] = [0] * len(data)\n",
    "\n",
    "for i in range(1, layers+1):\n",
    "    data['DensIRH' + str(i)] = [0] * len(data)\n",
    "    \n",
    "# Add columns for adjusted depth\n",
    "\n",
    "for i in range(1, layers+1):\n",
    "    data['AdjDepthIRH' + str(i)] = data['IRH' + str(i)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa59ba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code calculates the density adjustment. You can choose the target density and the \n",
    "# observed density profile\n",
    "\n",
    "# Calculate the density for each point:\n",
    "\n",
    "for i in range(1,layers+1):\n",
    "    for j in range(2000):\n",
    "        if not np.isnan(data.loc[j,'IRH' + str(i)]):\n",
    "            data.loc[j,'DensIRH' + str(i)] = DensityProfile(data.loc[j,'IRH' + str(i)])\n",
    "\n",
    "# This code calculates the equivalent depth after a density adjustment assuming a uniform\n",
    "# density of 900 kg m^{-3}. These calculations allow for an adjustment where NaN values appear.\n",
    "            \n",
    "for i in range(1,layers+1):\n",
    "    for j in range(len(data)):\n",
    "        if not np.isnan(data.loc[j,'AdjDepthIRH' + str(i)]):\n",
    "            k = i\n",
    "            while np.isnan(data.loc[j,'AdjDepthIRH' + str(k-1)]) and k>=0:\n",
    "                k = k - 1\n",
    "            a0 = data.loc[j,'AdjDepthIRH' + str(i)]\n",
    "            data.loc[j,'AdjDepthIRH' + str(i)] = data.loc[j,'AdjDepthIRH' + str(k-1)] \\\n",
    "                                             + ((data.loc[j,'AdjDepthIRH' + str(i)] \\\n",
    "                                               - data.loc[j,'AdjDepthIRH' + str(k-1)]) \\\n",
    "                                               * data.loc[j,'DensIRH' + str(i)]) / 900.0\n",
    "            a1 = data.loc[j,'AdjDepthIRH' + str(i)]\n",
    "            for l in range(i+1, layers+1):\n",
    "                data.loc[j,'AdjDepthIRH' + str(l)] = data.loc[j,'AdjDepthIRH' + str(l)] - (a0 - a1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad946de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "\n",
    "data.drop(columns='surface', inplace=True)\n",
    "\n",
    "for i in range(1,layers+1):\n",
    "    data.drop(columns='IRH' + str(i), inplace=True)\n",
    "    data.drop(columns='DensIRH' + str(i), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ca04b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work with BedMachine netcdf surface data to allow conversion of radar stratigraphy \n",
    "# depths to elevations\n",
    "\n",
    "surf = np.array(ds.variables[surf_name][:])\n",
    "X = np.array(ds.variables['x'][:])\n",
    "Y = np.array(ds.variables['y'][:])\n",
    "X.shape, Y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05159d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for interpolating data from the 2D grid\n",
    "\n",
    "data['Surface'] = np.nan * len(data)\n",
    "\n",
    "f = interpolate.interp2d(X, Y, surf, kind='linear')\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data['Surface'][i] = f(data['psX'][i], data['psY'][i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18629698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract depths from surface elevation for the stratigraphy elevation\n",
    "\n",
    "for i in range(1,layers+1):\n",
    "    data['StratElev' + str(i)]= data['Surface'] - data['AdjDepthIRH' + str(i)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f4fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "\n",
    "for i in range(0,layers+1):\n",
    "    data.drop(columns='AdjDepthIRH' + str(i), inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9905976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "\n",
    "from pathlib import Path  \n",
    "filepath = Path(output_path)  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "data.to_csv(filepath, na_rep='NaN', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45475a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f367f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8427080",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
